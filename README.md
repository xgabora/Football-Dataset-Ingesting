
# Football Match Data Processing & Feature Engineering Pipeline

This document outlines the technical process for ingesting, cleaning, enriching, and preparing [football match data](https://github.com/xgabora/Club-Football-Match-Data-2000-2025) for further analysis or modeling. The pipeline consists of several Python scripts that sequentially process data, generating intermediate Excel files.

## 1. Initial Setup and Requirements

### 1.1. Project Structure

It's recommended to organize the project as follows:

```
football_dataset_ingesting/
├── match_loading.py
├── elo_loading.py
├── assign_elo.py
├── calculate_form.py
├── assign_clusters.py
├── example_data/
│   └── E0.csv            # Example input match data
├── clusters/
│   ├── kmeans_model.pkl  # Pre-trained KMeans clustering model
│   └── robust_scaler.pkl # Pre-trained RobustScaler for features
├── output_data/          # Directory for all processed output files
└── requirements.txt
```

### 1.2. Python Environment

*   Python 3.8+ is recommended.
*   It is highly advised to use a virtual environment (venv) to manage dependencies.

### 1.3. Required Libraries

Install the necessary Python libraries using pip:
```bash
pip install -r requirements.txt
```
A `requirements.txt` file should be created containing:
```
pandas
numpy
requests
scikit-learn
openpyxl
```

### 1.4. Model Files

The clustering process relies on pre-trained models:
*   `clusters/kmeans_model.pkl`: A scikit-learn `KMeans` model object.
*   `clusters/robust_scaler.pkl`: A scikit-learn `RobustScaler` object.
These files must be present in the `clusters/` directory relative to where the `assign_clusters.py` script is run.

## 2. Data Acquisition

The pipeline processes data from two primary types of sources:

### 2.1. Match Data (e.g., `football-data.co.uk`)
*   **Source:** CSV files, typically downloaded from website `football-data.co.uk`. These files contain historical match results, scores, basic statistics (shots, fouls, corners), and prediction market odds for various leagues and seasons.
*   **Format:** CSV.
*   **Example:** An `E0.csv` file for the English Premier League would be placed in the `example_data/` directory. The `match_loading.py` script is configured to read from this location.

### 2.2. Club Elo Ratings (ClubElo API)
*   **Source:** The `api.clubelo.com` public API. This API provides daily Elo ratings for football clubs worldwide.
*   **Format:** The API returns data in a CSV-like text format.
*   **Method:** The `elo_loading.py` script makes HTTP GET requests to specific API endpoint `http://api.clubelo.com/YYYY-MM-DD` to fetch ratings for predefined dates.

## 3. Script Descriptions and Workflow

The pipeline consists of five main Python scripts, executed sequentially. Each script typically reads an Excel file generated by the previous step (except the first two) and outputs a new Excel file.

### 3.1. `match_loading.py` (Initial Match Data Processing)

*   **Input:** Raw match data CSV file (e.g., `example_data/E0.csv`).
*   **Purpose:** To read, clean, and standardize raw match data from various potential column names into a consistent format.
*   **Methods:**
    *   **Robust CSV Reading:** Attempts to read the CSV using multiple encodings and separators.
    *   **Column Name Cleaning:** Strips whitespace and removes special characters (including UTF-8 BOM) from column names.
    *   **Data Type Conversion:** Parses dates and times into standard formats (`YYYY-MM-DD`, `HH:MM:SS`).
    *   **Value Standardization:**
        *   Maps various source column names for results (e.g., `FTHG`, `HG`), statistics (e.g., `HS`, `HomeShots`), and odds (e.g., `B365H`, `AvgH`) to a predefined, consistent set of target column names using mapping dictionaries (`RESULT_COLUMNS`, `STATS_COLUMNS`, `ODDS_HIERARCHY`).
        *   Cleans numeric values and standardizes match result codes (H, D, A).
    *   **Parallel Processing:** Utilizes `concurrent.futures.ProcessPoolExecutor` to process chunks of the input DataFrame in parallel for improved performance on larger files.
*   **Output:** `output_data/processed_{input_filename_stem}.xlsx` (e.g., `output_data/processed_E0.xlsx`). This file contains the cleaned and standardized match data.

### 3.2. `elo_loading.py` (Fetching Club Elo Ratings)

*   **Input:** None (fetches directly from API).
*   **Purpose:** To retrieve historical Elo ratings for specific dates and for English teams (`ENG`) from the ClubElo API.
*   **Methods:**
    *   **API Interaction:** Makes HTTP GET requests to `api.clubelo.com` for a predefined list of dates (`SPECIFIC_DATES_TO_FETCH`).
    *   **Data Parsing:** Parses the CSV-formatted text response from the API.
    *   **Filtering:** Selects only records for teams where `Country` is "ENG".
    *   **Data Structuring:** Formats the fetched data (date, club, country, elo) into a list of dictionaries.
*   **Output:** `output_data/processed_elo.xlsx`. This file contains the fetched Elo ratings for English teams on the specified dates.

### 3.3. `assign_elo.py` (Assigning Elo Ratings to Matches)

*   **Input:**
    *   `output_data/processed_E0.xlsx` (cleaned match data)
    *   `output_data/processed_elo.xlsx` (Elo ratings)
*   **Purpose:** To enrich the match data by adding `HomeElo` and `AwayElo` ratings for each match.
*   **Methods:**
    *   **Data Loading & Preparation:** Loads both input Excel files. Converts date columns to `datetime.date` objects for accurate comparison. Sorts Elo ratings by club and date (descending) and groups them by team for efficient lookup.
    *   **Elo Assignment Logic (`get_closest_elo`):** For each match, it iterates through the historical Elo ratings of the home and away teams. It selects the most recent Elo rating for each team that is *on or before* the `MatchDate`. An optional lookback window (`ELO_LOOKBACK_DAYS`) can constrain how far back Elo ratings are considered.
*   **Output:** `output_data/matches_with_elo.xlsx`. This file contains the match data from `processed_E0.xlsx` augmented with `HomeElo` and `AwayElo` columns.

### 3.4. `calculate_form.py` (Calculating Team Form)

*   **Input:** `output_data/matches_with_elo.xlsx`.
*   **Purpose:** To calculate and add team form metrics (`Form3Home`, `Form5Home`, `Form3Away`, `Form5Away`) to each match. Form is based on points earned in the last N games.
*   **Methods:**
    *   **Data Loading & Preparation:** Loads the input Excel file. Converts `MatchDate` to `datetime.date` and ensures score columns (`FTHome`, `FTAway`) are numeric. Sorts matches by date chronologically.
    *   **Form Calculation Logic (`calculate_team_form`):**
        *   For each team in a given match, it looks at all matches played by that team *strictly before* the current match's date.
        *   It takes the N most recent of these past matches (where N is 3 or 5).
        *   If fewer than N past matches exist for the team, the form for that N-game window is recorded as `NaN` (Not a Number, appears blank in Excel).
        *   If N past matches exist, points are calculated (3 for a win, 1 for a draw, 0 for a loss) based on the `FTHome` and `FTAway` scores of those N matches.
        *   If any of the N required past matches have missing scores, the form is also `NaN`.
*   **Output:** `output_data/matches_with_form.xlsx`. This file contains the data from `matches_with_elo.xlsx` augmented with the four form columns.

### 3.5. `assign_clusters.py` (Assigning Cluster Probabilities to Matches)

*   **Input:**
    *   `output_data/matches_with_form.xlsx`
    *   `clusters/kmeans_model.pkl`
    *   `clusters/robust_scaler.pkl`
*   **Purpose:** To assign each match to predefined tactical/stylistic clusters based on engineered features and calculate the probability of belonging to each cluster.
*   **Methods:**
    *   **Model Loading (`load_models`):** Loads the pre-trained `RobustScaler` and `KMeans` models from `.pkl` files. Includes a fallback to create models with hardcoded centers if `.pkl` files are missing (though using the trained `.pkl` files is strongly preferred).
    *   **Feature Engineering (`prepare_features`):**
        *   Estimates missing Elo ratings using betting odds (`estimate_elo_from_odds`).
        *   Creates five key features: `ShotEfficiencyDiff`, `PossessionDominance`, `GamePhysicality`, `GameTempo`, and `EloDifferential`.
        *   Handles potential division-by-zero errors and fills remaining NaNs in features with their medians to ensure all matches can be processed.
    *   **Clustering & Probability Calculation (`calculate_cluster_probabilities`):**
        *   Scales the engineered features using the loaded `RobustScaler`.
        *   Calculates the Euclidean distances from each match's feature vector to the cluster centers of the loaded `KMeans` model.
        *   Converts these distances into probabilities using a softmax function with a specified temperature. This provides a "soft" assignment, indicating the likelihood of a match belonging to each of the predefined clusters (`CLUSTER_NAMES`).
    *   **Data Integration:** Joins the calculated cluster probabilities back to the main match DataFrame.
*   **Output:** `output_data/matches_with_clusters.xlsx`. This file contains the data from `matches_with_form.xlsx` augmented with columns for cluster probabilities (e.g., `C_LTH`, `C_HTB`, etc.).

## 4. Final Thoughts and Considerations

### 4.1. Current State

The pipeline successfully processes raw football data, enriches it with Elo ratings, calculates team form, and assigns stylistic cluster probabilities. The output is a comprehensive [dataset](https://github.com/xgabora/Club-Football-Match-Data-2000-2025) ready for further analysis or input into predictive models. The process is modular, with each script performing a distinct step and producing an intermediate Excel file, which aids in debugging and verification.

### 4.2. Key Considerations

*   **Input Data Consistency:** The reliability of the entire pipeline heavily depends on the consistency and quality of the input match data CSVs (column names, data formats). The `match_loading.py` script attempts to handle variations, but significant deviations might require code adjustments.
*   **Model Management:** The clustering step relies on pre-trained `.pkl` models. These models (scaler and KMeans) should be trained on a relevant and representative dataset. If the characteristics of incoming data change significantly, these models may need to be retrained. The fallback to predefined cluster centers is a stopgap and may not be optimal.
*   **Feature Engineering for Clustering:** The five features used for clustering (`ShotEfficiencyDiff`, `PossessionDominance`, `GamePhysicality`, `GameTempo`, `EloDifferential`) are critical. Their definitions and the way NaNs are handled (e.g., filling with median) can impact cluster assignments.
*   **Elo Estimation:** The logic for estimating Elo from odds is an approximation. Actual Elo ratings are preferred.
*   **Form Calculation:** The definition of "form" (points in last N games, handling of insufficient history) is specific. If scores are missing in past matches used for form calculation, the current implementation results in `NaN` for that form period.
*   **Database Usage:** The curation of [the dataset](https://github.com/xgabora/Club-Football-Match-Data-2000-2025) was actually made with the use of MySQL database. We strongly recommend using one to keep track of all matches loaded and easier manipulation with the data instead of using .xlsx or .csv files. 
